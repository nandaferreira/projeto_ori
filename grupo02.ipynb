{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dafe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import das bibliotecas\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698aa950",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60434fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Carregar o JSON\n",
    "with open(\"colecao - trabalho 01.json\", 'r', encoding='utf-8') as f:\n",
    "    colecao_documentos = json.load(f)\n",
    "\n",
    "# Criar DataFrame diretamente a partir da lista de dicionários\n",
    "df = pd.DataFrame(colecao_documentos)\n",
    "\n",
    "# Exibir informações sobre o DataFrame\n",
    "print(\"Forma do DataFrame:\", df.shape)\n",
    "print(\"\\nPrimeiras linhas:\")\n",
    "print(df.head())\n",
    "print(\"\\nColunas:\", df.columns.tolist())\n",
    "print(\"\\nTipos de dados:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nPrimeiro documento (completo):\")\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b693c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entender a estrutura do json e padronizar em uma estrutura manipulavel (dicionário ou lista?)\n",
    "\n",
    "\n",
    "#with open('colecao - trabalho 01.json', 'r', encoding='utf-8') as f:\n",
    "#    colecao_documentos = json.load(f)\n",
    "#print(colecao_documentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7de981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método 1: Simples e direto - usando pd.DataFrame()\n",
    "# Perfeito quando o JSON é um array de objetos com mesma estrutura\n",
    "\n",
    "df_simple = pd.DataFrame(colecao_documentos)\n",
    "\n",
    "print(\"=== MÉTODO 1: DataFrame Simples ===\")\n",
    "print(df_simple.shape)\n",
    "print(df_simple.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df68733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método 3: Preparar dados para processamento de NLP\n",
    "\n",
    "# Criar cópia do DataFrame para pré-processamento\n",
    "df_processado = df_simple.copy()\n",
    "\n",
    "# 1. Converter todos os textos para minúsculas\n",
    "df_processado['content_lower'] = df_processado['content'].str.lower()\n",
    "\n",
    "# 2. Remover quebras de linha múltiplas\n",
    "df_processado['content_clean'] = df_processado['content_lower'].str.replace(r'\\n+', ' ', regex=True)\n",
    "\n",
    "# 3. Remover espaços múltiplos\n",
    "df_processado['content_clean'] = df_processado['content_clean'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# 4. Remover espaços no início e fim\n",
    "df_processado['content_clean'] = df_processado['content_clean'].str.strip()\n",
    "\n",
    "print(\"=== MÉTODO 3: Normalização com Limpeza ===\")\n",
    "print(\"Forma:\", df_processado.shape)\n",
    "print(\"\\nColunas:\", df_processado.columns.tolist())\n",
    "print(\"\\nPrimeiro documento original:\")\n",
    "print(df_processado['content'].iloc[0][:200])\n",
    "print(\"\\nPrimeiro documento processado:\")\n",
    "print(df_processado['content_clean'].iloc[0][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6b6fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pré processamento dos dados\n",
    "\n",
    "# Para usar o sistema completo, execute no terminal:\n",
    "# python main.py\n",
    "\n",
    "# Testes rápidos do sistema no notebook:\n",
    "print(\"=\" * 60)\n",
    "print(\"TESTES RÁPIDOS DO SISTEMA DE INDEXAÇÃO\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cb6d4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\ferre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. ADICIONANDO DOCUMENTOS\n",
      "------------------------------------------------------------\n",
      "✓ D1 adicionado (1120 caracteres)\n",
      "✓ D2 adicionado (1080 caracteres)\n",
      "✓ D3 adicionado (1063 caracteres)\n",
      "✓ D4 adicionado (958 caracteres)\n",
      "✓ D5 adicionado (918 caracteres)\n",
      "\n",
      "Total de documentos: 5\n",
      "Total de palavras únicas: 222\n"
     ]
    }
   ],
   "source": [
    "# Teste 1: Inicializar o gerenciador e adicionar alguns documentos\n",
    "from gerenciador import GerenciadorColecao\n",
    "from search_engine import MotorBusca\n",
    "\n",
    "# Cria gerenciador\n",
    "gerenciador = GerenciadorColecao()\n",
    "\n",
    "# Carrega documentos do JSON\n",
    "documentos = gerenciador.carregar_json(\"colecao - trabalho 01.json\")\n",
    "\n",
    "# Adiciona os primeiros 5 documentos\n",
    "print(\"\\n1. ADICIONANDO DOCUMENTOS\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(min(5, len(documentos))):\n",
    "    doc = documentos[i]\n",
    "    gerenciador.adicionar_documento(\n",
    "        doc_id=i,\n",
    "        nome=doc[\"name\"],\n",
    "        conteudo=doc[\"content\"]\n",
    "    )\n",
    "    print(f\"✓ {doc['name']} adicionado ({len(doc['content'])} caracteres)\")\n",
    "\n",
    "print(f\"\\nTotal de documentos: {len(gerenciador.documentos)}\")\n",
    "print(f\"Total de palavras únicas: {len(gerenciador.vocabulario)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be068b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. VOCABULÁRIO\n",
      "------------------------------------------------------------\n",
      "Total de palavras únicas: 222\n",
      "Primeiras 20 palavras: [\"'estrut\", \"'fil\", \"'list\", \"'tabel\", \"'árvor\", 'abord', 'aceler', 'acess', 'acompanh', 'adapt', 'adequ', 'adic', 'ajud', 'algoritm', 'alt', 'ampli', 'apen', 'aplic', 'aproxim', 'atenç']\n",
      "\n",
      "3. MATRIZ TF-IDF (amostra)\n",
      "------------------------------------------------------------\n",
      "Documento        'estrut        'fil       'list      'tabel      'árvor       abord      aceler       acess\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "D0                    -           -           -           -           -           -           -           -\n",
      "D1                    -      0.0071           -           -      0.0071      0.0071           -           -\n",
      "D2                    -      0.0043           -           -           -           -      0.0116      0.0085\n",
      "D3                    -           -           -           -           -           -           -      0.0068\n",
      "D4                    -           -           -           -           -      0.0109           -      0.0027\n"
     ]
    }
   ],
   "source": [
    "# Teste 2: Exibir vocabulário e matriz TF-IDF\n",
    "print(\"\\n2. VOCABULÁRIO\")\n",
    "print(\"-\" * 60)\n",
    "vocab = gerenciador.obter_vocabulario_ordenado()\n",
    "print(f\"Total de palavras únicas: {len(vocab)}\")\n",
    "print(f\"Primeiras 20 palavras: {vocab[:20]}\")\n",
    "\n",
    "print(\"\\n3. MATRIZ TF-IDF (amostra)\")\n",
    "print(\"-\" * 60)\n",
    "dados, vocab_matriz = gerenciador.obter_matriz_tfidf_tabular()\n",
    "\n",
    "# Exibe matriz com os primeiros 8 termos\n",
    "print(f\"{'Documento':<12}\", end=\"\")\n",
    "for palavra in vocab_matriz[:8]:\n",
    "    print(f\"{palavra:>12}\", end=\"\")\n",
    "print()\n",
    "print(\"-\" * (12 + 12 * 8))\n",
    "\n",
    "for doc_id in sorted(dados.keys()):\n",
    "    print(f\"D{doc_id:<10}\", end=\"\")\n",
    "    for palavra in vocab_matriz[:8]:\n",
    "        valor = dados[doc_id][palavra]\n",
    "        if valor > 0:\n",
    "            print(f\"{valor:>12.4f}\", end=\"\")\n",
    "        else:\n",
    "            print(f\"{'-':>12}\", end=\"\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "391b6ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. ÍNDICE INVERTIDO (amostra)\n",
      "------------------------------------------------------------\n",
      "Total de palavras no índice: 222\n",
      "\n",
      " 1.         'estrut → D0:[12] | D1:[84] | D2:[86] | \n",
      " 2.            'fil → D1:[90] | D2:[89] | \n",
      " 3.           'list → D0:[15] | \n",
      " 4.          'tabel → D0:[54] | \n",
      " 5.          'árvor → D1:[87] | \n",
      " 6.           abord → D1:[66] | D4:[52] | \n",
      " 7.          aceler → D2:[60] | \n",
      " 8.           acess → D0:[32, 62] | D2:[19, 61] | D3:[20, 32] | D4:[55] | \n",
      " 9.        acompanh → D4:[21] | \n",
      "10.           adapt → D2:[30] | D3:[10] | D4:[29] | \n"
     ]
    }
   ],
   "source": [
    "# Teste 3: Índice Invertido\n",
    "print(\"\\n4. ÍNDICE INVERTIDO (amostra)\")\n",
    "print(\"-\" * 60)\n",
    "indice = gerenciador.obter_indice_invertido_formatado()\n",
    "print(f\"Total de palavras no índice: {len(indice)}\\n\")\n",
    "\n",
    "# Mostra primeiras 10 palavras do índice\n",
    "for i, palavra in enumerate(list(indice.keys())[:10], 1):\n",
    "    docs_info = indice[palavra]\n",
    "    print(f\"{i:2}. {palavra:>15} → \", end=\"\")\n",
    "    for doc_id in sorted(docs_info.keys()):\n",
    "        posicoes = docs_info[doc_id]\n",
    "        print(f\"D{doc_id}:{posicoes}\", end=\" | \")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d53d3f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. BUSCA BOOLEANA\n",
      "------------------------------------------------------------\n",
      "Consulta: 'estrutura AND dados'\n",
      "Resultados: 5 documento(s)\n",
      "  - D1\n",
      "  - D2\n",
      "  - D3\n",
      "  - D4\n",
      "  - D5\n"
     ]
    }
   ],
   "source": [
    "# Teste 4: Motor de Busca - Busca Booleana\n",
    "motor_busca = MotorBusca(gerenciador)\n",
    "\n",
    "print(\"\\n5. BUSCA BOOLEANA\")\n",
    "print(\"-\" * 60)\n",
    "consulta_booleana = \"estrutura AND dados\"\n",
    "resultados = motor_busca.busca_booleana(consulta_booleana)\n",
    "print(f\"Consulta: '{consulta_booleana}'\")\n",
    "print(f\"Resultados: {len(resultados)} documento(s)\")\n",
    "for doc_id, nome in resultados:\n",
    "    print(f\"  - {nome}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e11046ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. BUSCA POR SIMILARIDADE (COSSENO)\n",
      "------------------------------------------------------------\n",
      "Consulta: 'estrutura de dados'\n",
      "Top 5 resultados por similaridade:\n",
      "\n",
      "Rank  Doc      Similaridade    Conteúdo                      \n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Teste 5: Busca por Similaridade\n",
    "print(\"\\n6. BUSCA POR SIMILARIDADE (COSSENO)\")\n",
    "print(\"-\" * 60)\n",
    "consulta_similaridade = \"estrutura de dados\"\n",
    "resultados_sim = motor_busca.busca_similaridade_cosseno(consulta_similaridade, top_k=5)\n",
    "print(f\"Consulta: '{consulta_similaridade}'\")\n",
    "print(f\"Top 5 resultados por similaridade:\\n\")\n",
    "print(f\"{'Rank':<5} {'Doc':<8} {'Similaridade':<15} {'Conteúdo':<30}\")\n",
    "print(\"-\" * 60)\n",
    "for i, (doc_id, nome, score) in enumerate(resultados_sim, 1):\n",
    "    conteudo = gerenciador.documentos[doc_id]['content'][:25]\n",
    "    print(f\"{i:<5} {nome:<8} {score:<15.4f} {conteudo}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef76e4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. BUSCA POR FRASES\n",
      "------------------------------------------------------------\n",
      "Consulta: 'lista encadeada simples'\n",
      "Resultados encontrados:\n",
      "\n",
      "Rank  Doc      Ocorrências     Conteúdo                      \n",
      "------------------------------------------------------------\n",
      "1     D2       1               O estudo de estruturas de...\n",
      "2     D3       1               Projetar algoritmos que l...\n",
      "3     D4       1               Em muitos sistemas modern...\n",
      "4     D5       1               Ao projetar uma aplicação...\n",
      "\n",
      "============================================================\n",
      "RESUMO DO TESTE\n",
      "============================================================\n",
      "Total de documentos:        5\n",
      "Total de palavras únicas:   222\n",
      "Total de palavras:          463\n",
      "Média de palavras por doc:  92.60\n"
     ]
    }
   ],
   "source": [
    "# Teste 6: Busca por Frases\n",
    "print(\"\\n7. BUSCA POR FRASES\")\n",
    "print(\"-\" * 60)\n",
    "consulta_frase = \"lista encadeada simples\"\n",
    "resultados_frase = motor_busca.busca_por_frases(consulta_frase, top_k=5)\n",
    "print(f\"Consulta: '{consulta_frase}'\")\n",
    "print(f\"Resultados encontrados:\\n\")\n",
    "\n",
    "if resultados_frase:\n",
    "    print(f\"{'Rank':<5} {'Doc':<8} {'Ocorrências':<15} {'Conteúdo':<30}\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, (doc_id, nome, score) in enumerate(resultados_frase, 1):\n",
    "        conteudo = gerenciador.documentos[doc_id]['content'][:25]\n",
    "        print(f\"{i:<5} {nome:<8} {score:<15d} {conteudo}...\")\n",
    "else:\n",
    "    print(\"Nenhum resultado encontrado. Tente outro termo.\")\n",
    "\n",
    "# Resumo final\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESUMO DO TESTE\")\n",
    "print(\"=\" * 60)\n",
    "stats = gerenciador.obter_estatisticas()\n",
    "print(f\"Total de documentos:        {stats['total_documentos']}\")\n",
    "print(f\"Total de palavras únicas:   {stats['total_palavras_unicas']}\")\n",
    "print(f\"Total de palavras:          {stats['total_palavras']}\")\n",
    "print(f\"Média de palavras por doc:  {stats['media_palavras_por_doc']:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
