================================================================================
                    REFERÊNCIA RÁPIDA - COMANDOS
================================================================================

EXECUTAR O SISTEMA:

1. Menu Interativo (Recomendado):
   $ python main.py
   
   Opções principais:
   1 - Adicionar um documento
   2 - Adicionar todos os documentos
   3 - Remover um documento
   4 - Listar documentos
   5 - Exibir vocabulário
   6 - Exibir matriz TF-IDF
   7 - Exibir índice invertido
   8 - Busca booleana
   9 - Busca por similaridade
   10 - Busca por frases
   11 - Exibir estatísticas
   0 - Sair

2. Teste Automático:
   $ python teste_rapido.py
   
   Executa todos os testes em sequência

3. Notebook Jupyter:
   Abra: grupo02.ipynb
   Execute as células preparadas

================================================================================
                    CONSULTAS DE EXEMPLO
================================================================================

BUSCA BOOLEANA - Operadores AND/OR/NOT

  "estrutura AND dados"
  → Documentos que contêm AMBOS os termos
  
  "árvore OR grafo"
  → Documentos que contêm UM OU OUTRO termo
  
  "lista NOT linear"
  → Documentos com "lista" MAS SEM "linear"
  
  "hash AND colisão AND tratamento"
  → Documentos que contêm os 3 termos

BUSCA POR SIMILARIDADE - Ranking de relevância

  "estrutura de dados"
  → Retorna documentos ordenados por similaridade
  
  "árvore balanceada"
  → Top 5 mais similares
  
  "hash tratamento colisões"
  → Ranking completo

BUSCA POR FRASES - Sequências exatas

  "lista encadeada simples"
  → Encontra a frase completa
  
  "tabela hash com tratamento de colisões"
  → Busca a sequência exata
  
  "estrutura de dados linear"
  → Palavras devem estar consecutivas

================================================================================
                    ESTRUTURAS DE DADOS
================================================================================

VOCABULÁRIO:
  Set de palavras únicas após processamento
  Exemplo: {'estrutura', 'dado', 'linear', 'árvore', ...}

FREQUÊNCIAS POR DOCUMENTO:
  {doc_id: {palavra: frequência}}
  Exemplo: {0: {'estrutura': 5, 'dado': 3, 'linear': 2}}

MATRIZ TF-IDF:
  {doc_id: {palavra: valor_tfidf}}
  Valores entre 0 e ~0.15
  Exemplo: {0: {'estrutura': 0.154, 'dado': 0.092}}

ÍNDICE INVERTIDO:
  {palavra: {doc_id: [posições]}}
  Permite localização de sequências
  Exemplo: {'estrutura': {0: [12, 45, 78], 1: [5, 23]}}

================================================================================
                    ARQUIVO JSON
================================================================================

Estrutura do "colecao - trabalho 01.json":

[
  {
    "name": "D1",
    "content": "Texto completo do documento..."
  },
  {
    "name": "D2",
    "content": "Texto completo do documento..."
  },
  ...
]

Total: 50 documentos (D1 a D50)
Tamanho: ~150KB
Tópicos: Estruturas de dados e POO

================================================================================
                    VARIÁVEIS DE AMBIENTE
================================================================================

Nenhuma variável de ambiente é necessária.
O sistema baixa automaticamente recursos do NLTK na primeira execução.

Para ambiente sem internet, pré-instale:
  python -m nltk.downloader stopwords rslp

================================================================================
                    TROUBLESHOOTING
================================================================================

PROBLEMA: ModuleNotFoundError: No module named 'nltk'
SOLUÇÃO:  pip install nltk

PROBLEMA: Busca retorna resultados vazios
SOLUÇÃO:  Verifique se documentos foram adicionados
          Tente termos simples: "estrutura" em vez de "estruturas"
          Use aspas para frases: "lista encadeada"

PROBLEMA: Tela muito longa/muitos resultados
SOLUÇÃO:  Use top_k para limitar: "5" quando perguntado

PROBLEMA: Arquivo JSON não encontrado
SOLUÇÃO:  Verifique se "colecao - trabalho 01.json" está no diretório

PROBLEMA: Lentidão com todos os 50 documentos
SOLUÇÃO:  Normal para hardware antigo
          Primeiros testes com 5-10 documentos
          Depois escale para 50

================================================================================
                    ARQUIVOS DE DOCUMENTAÇÃO
================================================================================

README.md
  • Visão geral completa
  • Exemplos detalhados
  • Instruções técnicas
  • Notas de desenvolvimento

GUIA_SISTEMA.txt
  • Menu interativo detalhado
  • Componentes técnicos
  • Fluxos de trabalho
  • Exemplos passo a passo

RESUMO_IMPLEMENTACAO.txt (este arquivo)
  • Estrutura do projeto
  • Funcionalidades implementadas
  • Resultados dos testes
  • Referência rápida

================================================================================
                    REQUISITOS MÍNIMOS
================================================================================

Python:    3.8+
RAM:       256MB (mínimo), 512MB (recomendado)
Disco:     50MB (sistema + 150KB dados)
Internet:  Para primeira execução (download de recursos NLTK)

Testado em:
  ✓ Windows 10/11 com Python 3.13
  ✓ Python 3.8, 3.9, 3.10, 3.11, 3.12

================================================================================
                    TEMPO DE EXECUÇÃO
================================================================================

Operação                Tempo Típico
────────────────────────────────────
Carregar 5 documentos   ~380ms
Gerar vocabulário       ~10ms
Calcular TF-IDF        ~50ms
Busca booleana         ~19ms
Busca similaridade     ~14ms
Busca por frases       ~5ms
Adicionar 1 documento  ~50-100ms
Remover 1 documento    ~30ms

Total (teste completo)  ~600ms para 5 documentos

================================================================================
                    DIMENSÕES TÍPICAS
================================================================================

Com 5 documentos:
  • Vocabulário:        222 palavras únicas
  • Total de palavras:  463
  • Matriz TF-IDF:      5×222 = até 1110 valores

Com 50 documentos:
  • Vocabulário:        ~2000-3000 palavras únicas
  • Total de palavras:  ~4500-5500
  • Matriz TF-IDF:      50×2500 = até 125000 valores

Com 1000 documentos:
  • Vocabulário:        ~10000+ palavras únicas
  • Total de palavras:  ~100000+
  • Recomenda-se matriz esparsa

================================================================================
                    DÚVIDAS FREQUENTES
================================================================================

P: Posso adicionar meus próprios documentos?
R: Sim! Modifique o JSON "colecao - trabalho 01.json" com seus dados.

P: Qual é o tamanho máximo de documentos?
R: Testado com coleção de 50 documentos (~2500 palavras únicas).
   Com 1000+ documentos, considere otimizações.

P: Posso usar outro idioma?
R: Sim, mas precisará baixar stopwords e stemmer para o idioma desejado.

P: Como salvo o índice?
R: Use pickle ou JSON para serialização:
   import pickle
   with open('indice.pkl', 'wb') as f:
       pickle.dump(gerenciador, f)

P: Como integro com API web?
R: Use Flask ou FastAPI:
   from flask import Flask, request
   app = Flask(__name__)
   @app.route('/busca', methods=['POST'])
   def busca():
       # Seu código aqui
       return jsonify(resultados)

P: Posso fazer busca case-sensitive?
R: Não, o sistema processa tudo em minúsculas.
   Para case-sensitive, remova a conversão em preprocessor.py

================================================================================
                    LICENÇA E CRÉDITOS
================================================================================

Trabalho acadêmico para disciplina:
  Organização e Recuperação de Informação (ORI)

Bibliotecas utilizadas:
  • NLTK - Natural Language Toolkit (open source)
  • Python Standard Library

Desenvolvido em: Dezembro 2024

================================================================================
