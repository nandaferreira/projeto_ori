{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpKAjcx0kBE-",
        "outputId": "6e0a54fb-f261-48ed-b739-6383090ab6d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arquivo 'colecao - trabalho 01.json' criado/atualizado com sucesso no formato de dicionário.\n"
          ]
        }
      ],
      "source": [
        "#Rode isso para garantir que o arquivo exista na primeira execução\n",
        "import json\n",
        "\n",
        "dados_iniciais = {\n",
        "  \"D1\": \"Salve lindo pendão esperança símbolo augusto paz nobre presença lembrança grandeza Pátria traz\",\n",
        "  \"D2\": \"podeis Pátria filhos Ver contente mãe gentil raiou liberdade horizonte Brasil\",\n",
        "  \"D3\": \"Ouviram Ipiranga margens plácidas povo heróico brado retumbante sol Liberdade raios fúlgidos Brilhou céu Pátria instante\",\n",
        "}\n",
        "\n",
        "nome_arquivo = 'colecao - trabalho 01.json'\n",
        "with open(nome_arquivo, 'w', encoding='utf-8') as f:\n",
        "    json.dump(dados_iniciais, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"Arquivo '{nome_arquivo}' criado/atualizado com sucesso no formato de dicionário.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdgxQC-XnKE-",
        "outputId": "7db6f27a-0bec-439a-dcd8-3201b6af215d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "from math import log2\n",
        "from collections import defaultdict\n",
        "import os\n",
        "\n",
        "# Ana Alice Cordeiro - 12211BCC028;\n",
        "# Bruno Castro - 12211BCC004;\n",
        "# Ester Freitas - 12211BCC036;\n",
        "# Fernanda Ferreira - 12211BCC043;\n",
        "# João Vitor Feijó - 12311BCC061\n",
        "\n",
        "\n",
        "class SRISystem:\n",
        "\n",
        "    documentos = {}\n",
        "    tokens_documentos = {}\n",
        "    vocabulario = []\n",
        "    indice_invertido = defaultdict(lambda: defaultdict(list))\n",
        "    matriz_tfidf = None\n",
        "    series_idf = None\n",
        "    CAMINHO_ARQUIVO_JSON = 'colecao - trabalho 01.json'\n",
        "\n",
        "    def __init__(self):\n",
        "        self.carregar_colecao_json(self.CAMINHO_ARQUIVO_JSON, carregamento_inicial=True)\n",
        "\n",
        "    def _limpar_e_tokenizar(self, texto):\n",
        "        texto = texto.lower()\n",
        "        texto = re.sub(r'[^a-záàâãéèêíïóôõöúçñ\\s]', '', texto)\n",
        "        return [termo for termo in texto.split() if termo]\n",
        "\n",
        "    def _atualizar_indexacao(self):\n",
        "\n",
        "        todos_tokens = []\n",
        "        self.tokens_documentos = {}\n",
        "        for id_doc, texto in self.documentos.items():\n",
        "            tokens = self._limpar_e_tokenizar(texto)\n",
        "            self.tokens_documentos[id_doc] = tokens\n",
        "            todos_tokens.extend(tokens)\n",
        "        self.vocabulario = sorted(list(set(todos_tokens)))\n",
        "\n",
        "        self.indice_invertido = defaultdict(lambda: defaultdict(list))\n",
        "        for id_doc, tokens in self.tokens_documentos.items():\n",
        "            for posicao, termo in enumerate(tokens):\n",
        "                self.indice_invertido[termo][id_doc].append(posicao)\n",
        "\n",
        "        if self.documentos:\n",
        "            self._calcular_matrizes_tfidf()\n",
        "        else:\n",
        "            self.matriz_tfidf = None\n",
        "            self.series_idf = None\n",
        "\n",
        "    def _salvar_colecao_json(self):\n",
        "        try:\n",
        "            dados_para_salvar = {id_doc: texto for id_doc, texto in self.documentos.items()}\n",
        "\n",
        "            with open(self.CAMINHO_ARQUIVO_JSON, 'w', encoding='utf-8') as f:\n",
        "                json.dump(dados_para_salvar, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "            print(f\"\\n[Persistência] Arquivo '{self.CAMINHO_ARQUIVO_JSON}' atualizado.\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\n[Persistência] ERRO ao salvar a coleção: {e}\")\n",
        "\n",
        "    def carregar_colecao_json(self, caminho_arquivo, carregamento_inicial=False):\n",
        "        try:\n",
        "            with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
        "                dados = json.load(f)\n",
        "\n",
        "            if isinstance(dados, list):\n",
        "                novos_documentos = {}\n",
        "                padrao = re.compile(r'^\\s*([a-z]\\d+)\\s*:\\s*(.*)', re.IGNORECASE)\n",
        "                for entrada in dados:\n",
        "                    match = padrao.match(entrada)\n",
        "                    if match:\n",
        "                        novos_documentos[match.group(1).upper()] = match.group(2).strip()\n",
        "            elif isinstance(dados, dict):\n",
        "                 novos_documentos = {chave.upper(): valor for chave, valor in dados.items()}\n",
        "            else:\n",
        "                print(f\"ERRO: Formato JSON inesperado ({type(dados)}).\")\n",
        "                return\n",
        "\n",
        "            novos_documentos_contados = 0\n",
        "            for id_doc, texto in novos_documentos.items():\n",
        "                if id_doc not in self.documentos:\n",
        "                    self.documentos[id_doc] = texto\n",
        "                    novos_documentos_contados += 1\n",
        "\n",
        "            self._atualizar_indexacao()\n",
        "\n",
        "            if not carregamento_inicial:\n",
        "                print(f\"SUCESSO: {novos_documentos_contados} documentos novos carregados e sistema indexado.\")\n",
        "                self._salvar_colecao_json()\n",
        "            else:\n",
        "                 print(f\"SUCESSO: Inicialização com {len(self.documentos)} documentos carregados.\")\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            if not carregamento_inicial:\n",
        "                 print(f\"ERRO: Arquivo '{caminho_arquivo}' não encontrado.\")\n",
        "            pass\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"ERRO: Formato JSON inválido no arquivo '{caminho_arquivo}'.\")\n",
        "        except Exception as e:\n",
        "            print(f\"ERRO: Falha ao carregar a coleção: {e}\")\n",
        "\n",
        "    def adicionar_documento(self, id_doc, texto):\n",
        "        self.documentos[id_doc] = texto\n",
        "        self._atualizar_indexacao()\n",
        "        self._salvar_colecao_json()\n",
        "        print(f\"SUCESSO: Documento '{id_doc}' adicionado/atualizado.\")\n",
        "\n",
        "    def remover_documento(self, id_doc):\n",
        "        if id_doc in self.documentos:\n",
        "            del self.documentos[id_doc]\n",
        "            self._atualizar_indexacao()\n",
        "            self._salvar_colecao_json()\n",
        "            print(f\"SUCESSO: Documento '{id_doc}' removido.\")\n",
        "            return True\n",
        "        print(f\"ERRO: Documento '{id_doc}' não encontrado.\")\n",
        "        return False\n",
        "\n",
        "    def _calcular_tf_simples(self):\n",
        "        nomes_docs = list(self.documentos.keys())\n",
        "        matriz_tf = pd.DataFrame(0, index=self.vocabulario, columns=nomes_docs)\n",
        "        for id_doc in nomes_docs:\n",
        "            for termo in self.tokens_documentos[id_doc]:\n",
        "                if termo in self.vocabulario:\n",
        "                    matriz_tf.loc[termo, id_doc] += 1\n",
        "        return matriz_tf\n",
        "\n",
        "    def _calcular_tf_log(self, matriz_tf_simples):\n",
        "        matriz_tf_log = matriz_tf_simples.apply(lambda coluna: coluna.map(lambda x: 1 + log2(x) if x > 0 else 0.0))\n",
        "        return matriz_tf_log\n",
        "\n",
        "    def _calcular_idf(self, matriz_tf_simples):\n",
        "        N = matriz_tf_simples.shape[1]\n",
        "        ni = (matriz_tf_simples > 0).sum(axis=1)\n",
        "        idf = np.log2(N / ni)\n",
        "        return pd.Series(idf, index=matriz_tf_simples.index, name=\"IDF\")\n",
        "\n",
        "    def _calcular_matrizes_tfidf(self):\n",
        "        matriz_tf_simples = self._calcular_tf_simples()\n",
        "        self.series_idf = self._calcular_idf(matriz_tf_simples)\n",
        "        matriz_tf_log = self._calcular_tf_log(matriz_tf_simples)\n",
        "        self.matriz_tfidf = matriz_tf_log.mul(self.series_idf, axis=0)\n",
        "\n",
        "    def exibir_vocabulario(self):\n",
        "        if not self.vocabulario:\n",
        "             print(\"AVISO: Vocabulário vazio\")\n",
        "             return\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(f\"VOCABULÁRIO ATUAL (Tamanho: {len(self.vocabulario)})\")\n",
        "        print(\"=\" * 50)\n",
        "        print(\", \".join(self.vocabulario))\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    def exibir_matriz_tfidf(self):\n",
        "        if self.matriz_tfidf is None:\n",
        "            print(\"AVISO: Matriz TF-IDF não calculada ou coleção vazia.\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"MATRIZ TF-IDF (TF-Log * IDF)\")\n",
        "        print(\"=\" * 50)\n",
        "        print(self.matriz_tfidf.round(4))\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    def exibir_indice_invertido(self):\n",
        "        if not self.indice_invertido:\n",
        "            print(\"AVISO: Índice Invertido está vazio.\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"ÍNDICE INVERTIDO COMPLETO (POSIÇÕES)\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        # Iterar e exibir TODOS os termos\n",
        "        for termo, lista_postagem in self.indice_invertido.items():\n",
        "            string_postagens = \", \".join([f\"{id_doc}: {pos}\" for id_doc, pos in lista_postagem.items()])\n",
        "            print(f\"{termo}: {{{string_postagens}}}\")\n",
        "\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    def consulta_booleana(self, consulta):\n",
        "        consulta_normalizada = consulta.lower()\n",
        "\n",
        "        if ' and not ' in consulta_normalizada:\n",
        "            t1, t2 = [t.strip() for t in consulta_normalizada.split(' and not ')]\n",
        "            op_simples = 'AND NOT'\n",
        "\n",
        "        elif ' and ' in consulta_normalizada:\n",
        "            t1, t2 = [t.strip() for t in consulta_normalizada.split(' and ')]\n",
        "            op_simples = 'AND'\n",
        "\n",
        "        elif ' or ' in consulta_normalizada:\n",
        "            t1, t2 = [t.strip() for t in consulta_normalizada.split(' or ')]\n",
        "            op_simples = 'OR'\n",
        "\n",
        "        else:\n",
        "            return \"ERRO: Formato inválido. Use 'termo1 AND termo2', 'termo1 OR termo2', ou 'termo1 AND NOT termo2'.\"\n",
        "\n",
        "        t1 = self._limpar_e_tokenizar(t1)[0] if self._limpar_e_tokenizar(t1) else ''\n",
        "        t2 = self._limpar_e_tokenizar(t2)[0] if self._limpar_e_tokenizar(t2) else ''\n",
        "\n",
        "        if not t1 or not t2:\n",
        "            return \"ERRO: A consulta deve conter dois termos válidos.\"\n",
        "\n",
        "        set1 = set(self.indice_invertido.get(t1, {}).keys())\n",
        "        set2 = set(self.indice_invertido.get(t2, {}).keys())\n",
        "\n",
        "        if op_simples == 'AND':\n",
        "            resultado = set1.intersection(set2)\n",
        "        elif op_simples == 'OR':\n",
        "            resultado = set1.union(set2)\n",
        "        elif op_simples == 'AND NOT':\n",
        "            resultado = set1.difference(set2)\n",
        "        else:\n",
        "            return \"ERRO interno no operador.\"\n",
        "\n",
        "        return f\"Resultado da Consulta Booleana ('{t1.upper()} {op_simples} {t2.upper()}'): {sorted(list(resultado)) if resultado else 'Nenhum documento'}\"\n",
        "\n",
        "\n",
        "    def consulta_similaridade(self, consulta):\n",
        "        if self.matriz_tfidf is None or self.series_idf is None:\n",
        "            return \"ERRO: Matriz TF-IDF não calculada ou coleção vazia.\"\n",
        "\n",
        "        tokens_consulta = self._limpar_e_tokenizar(consulta)\n",
        "        serie_tf_consulta = pd.Series([tokens_consulta.count(termo) if termo in tokens_consulta else 0 for termo in self.vocabulario], index=self.vocabulario)\n",
        "\n",
        "        serie_tf_log_consulta = serie_tf_consulta.map(lambda x: 1 + log2(x) if x > 0 else 0.0)\n",
        "        serie_tfidf_consulta = serie_tf_log_consulta.mul(self.series_idf).fillna(0.0)\n",
        "\n",
        "        norma_consulta = np.linalg.norm(serie_tfidf_consulta)\n",
        "        if norma_consulta == 0:\n",
        "            return \"AVISO: Consulta não contém termos do vocabulário indexado.\"\n",
        "\n",
        "        similaridades = {}\n",
        "        for id_doc in self.documentos.keys():\n",
        "            vetor_doc = self.matriz_tfidf[id_doc].fillna(0.0)\n",
        "            norma_doc = np.linalg.norm(vetor_doc)\n",
        "\n",
        "            numerador = np.dot(serie_tfidf_consulta, vetor_doc)\n",
        "            denominador = norma_consulta * norma_doc\n",
        "\n",
        "            sim = numerador / denominador if denominador > 0 else 0.0\n",
        "            similaridades[id_doc] = sim\n",
        "\n",
        "        resultados_ranqueados = dict(sorted(similaridades.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "        saida = [\"\\nResultado Ranqueado (Similaridade do Cosseno):\"]\n",
        "        saida.extend([f\"Documento {id_doc}: Score {score:.4f}\" for id_doc, score in resultados_ranqueados.items() if score > 0])\n",
        "        return \"\\n\".join(saida) if len(saida) > 1 else \"Nenhum documento relevante encontrado.\"\n",
        "\n",
        "\n",
        "    def consulta_frase(self, frase):\n",
        "        tokens = self._limpar_e_tokenizar(frase)\n",
        "        if not tokens: return \"AVISO: Frase de consulta vazia.\"\n",
        "\n",
        "        primeiro_termo = tokens[0]\n",
        "        candidatos = set(self.indice_invertido.get(primeiro_termo, {}).keys())\n",
        "        documentos_finais = set()\n",
        "\n",
        "        for id_doc in candidatos:\n",
        "            posicoes_primeiro = self.indice_invertido[primeiro_termo][id_doc]\n",
        "\n",
        "            for posicao_inicial in posicoes_primeiro:\n",
        "                combinacao_correta = True\n",
        "                for i, termo in enumerate(tokens[1:]):\n",
        "                    posicao_esperada = posicao_inicial + i + 1\n",
        "\n",
        "                    if id_doc not in self.indice_invertido.get(termo, {}) or \\\n",
        "                       posicao_esperada not in self.indice_invertido[termo][id_doc]:\n",
        "                        combinacao_correta = False\n",
        "                        break\n",
        "\n",
        "                if combinacao_correta:\n",
        "                    documentos_finais.add(id_doc)\n",
        "                    break\n",
        "\n",
        "        return f\"Resultado da Consulta por Frase '{frase.upper()}': {sorted(list(documentos_finais)) if documentos_finais else 'Nenhum documento'}\"\n",
        "\n",
        "    def menu_execucao(self):\n",
        "        if not self.documentos:\n",
        "             self.documentos = {}\n",
        "             self._atualizar_indexacao()\n",
        "\n",
        "        while True:\n",
        "            print(\"\\n\" + \"=\" * 60)\n",
        "            print(\"SISTEMA DE RECUPERAÇÃO DA INFORMAÇÃO DO GRUPO 2 :)\")\n",
        "            print(\"=\" * 60)\n",
        "            print(\"Documentos indexados:\", sorted(list(self.documentos.keys())))\n",
        "            print(\"\\n--- GERENCIAMENTO E EXIBIÇÃO ---\")\n",
        "            print(\"1. Carregar/Recarregar documentos de JSON (Atualiza Arquivo)\")\n",
        "            print(\"2. Adicionar/Atualizar Documento (Salva no Arquivo)\")\n",
        "            print(\"3. Remover Documento (Salva no Arquivo)\")\n",
        "            print(\"4. Exibir Vocabulário\")\n",
        "            print(\"5. Exibir Índice Invertido Completo\")\n",
        "            print(\"6. Exibir Matriz TF-IDF\")\n",
        "            print(\"\\n--- CONSULTAS ---\")\n",
        "            print(\"7. Consulta Booleana (Ex: termo AND termo)\")\n",
        "            print(\"8. Consulta por Similaridade\")\n",
        "            print(\"9. Consulta por Frase Exata (Ex: 'trancando a faculdade')\")\n",
        "            print(\"\\n0. Sair\")\n",
        "\n",
        "            escolha = input(\"\\nSelecione uma opção: \").strip()\n",
        "\n",
        "            if escolha == '1':\n",
        "                self.carregar_colecao_json(self.CAMINHO_ARQUIVO_JSON)\n",
        "            elif escolha == '2':\n",
        "                id_doc = input(\"ID do documento (Ex: D5): \").strip().upper()\n",
        "                texto = input(\"Texto do documento: \").strip()\n",
        "                if id_doc and texto: self.adicionar_documento(id_doc, texto)\n",
        "            elif escolha == '3':\n",
        "                id_doc = input(\"ID do documento a remover: \").strip().upper()\n",
        "                self.remover_documento(id_doc)\n",
        "            elif escolha == '4':\n",
        "                self.exibir_vocabulario()\n",
        "            elif escolha == '5':\n",
        "                self.exibir_indice_invertido()\n",
        "            elif escolha == '6':\n",
        "                self.exibir_matriz_tfidf()\n",
        "            elif escolha == '7':\n",
        "                consulta = input(\"Consulta Booleana (termo1 AND/OR/NOT termo2): \").strip()\n",
        "                print(self.consulta_booleana(consulta))\n",
        "            elif escolha == '8':\n",
        "                consulta = input(\"Consulta por Similaridade: \").strip()\n",
        "                print(self.consulta_similaridade(consulta))\n",
        "            elif escolha == '9':\n",
        "                consulta = input(\"Consulta por Frase Exata: \").strip()\n",
        "                print(self.consulta_frase(consulta))\n",
        "            elif escolha == '0':\n",
        "                print(\"Encerrando o SRI. Sucesso!\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"Opção inválida.\")\n",
        "\n",
        "sris = SRISystem()\n",
        "sris.menu_execucao()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
